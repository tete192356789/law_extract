{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ddbbfd-e3af-45d2-96f3-a7b4509064c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from jsonpath_ng import jsonpath,parse\n",
    "import re\n",
    "import html2text\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e33c2d0-ce82-4930-b390-667e7aaf004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(json_data:list):\n",
    "    law_list = []\n",
    "    ann_list = []\n",
    "    for row in json_data:\n",
    "        if 'rows' in row.keys():\n",
    "            latest_update_found = False\n",
    "            law_count = 0\n",
    "            latest_law_data = None\n",
    "            \n",
    "            for law_data in row['rows']:\n",
    "                \n",
    "                #if no rows in keys then it's law record, if rows in keys it's folder not record\n",
    "                #check latest update law 'ฉบับ update ล่าสุด' in nm or 'UPDATE' in id\n",
    "                if 'rows' not in law_data.keys():\n",
    "                    law_count += 1\n",
    "                    if 'ฉบับ update ล่าสุด' in h.handle(law_data['data'][0]['value']) or 'UPDATE' in law_data['id']:\n",
    "                        latest_update_found = True\n",
    "                        latest_law_data = law_data\n",
    "                        break\n",
    "            #if no 'ฉบับ update ล่าสุด' in nm and 'UPDATE' in id and only1 record in main folder, it's mean that is latest law\n",
    "            if not latest_update_found and law_count == 1:\n",
    "                #get the first one law in main folder\n",
    "                latest_law_data = next(law_data for law_data in row['rows'] if 'rows' not in law_data.keys())\n",
    "    \n",
    "            \n",
    "            for law_data in row['rows']:\n",
    "                #law filter\n",
    "                if 'rows' not in law_data.keys():\n",
    "                    law_d = {}\n",
    "                    law_d['main_id'] = row['id']\n",
    "                    law_d['name'] = row['data'][0]['value']\n",
    "                    law_d['law_id'] = law_data['id']\n",
    "                    law_d['law_nm'] = h.handle(law_data['data'][0]['value'])\n",
    "                    law_d['law_link'] = law_data['data'][1]\n",
    "                    law_d['latest_update'] = (law_data == latest_law_data)\n",
    "                    law_list.append(law_d)\n",
    "                else:\n",
    "                #folder\n",
    "                    for ann_data in law_data['rows']:\n",
    "                        ann_d = {}\n",
    "                        ann_d['main_id'] = row['id']\n",
    "                        ann_d['name'] = row['data'][0]['value']\n",
    "                        ann_d['announce_id'] = law_data['id']\n",
    "                        ann_d['announce_type_nm'] = h.handle(law_data['data'][0]['value'])\n",
    "                        ann_d['announce_sub_id'] = ann_data['id']\n",
    "                        ann_d['announce_name'] = h.handle(ann_data['data'][0]['value'])\n",
    "                        ann_d['announce_link'] = ann_data['data'][1]\n",
    "                        ann_d['latest_update'] = False  # Announcements are not considered for latest update\n",
    "                        ann_list.append(ann_d)\n",
    "    return law_list , ann_list\n",
    "# law_df = pd.DataFrame(law_list)\n",
    "# ann_df = pd.DataFrame(ann_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09fa09cd-3b13-4f6c-9fe4-8b602bf4838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Apply Function for extract law_link column in law_df.\n",
    "def extract_links(html):\n",
    "    links = {}\n",
    "    pattern = r\"href='(https://krisdika\\.ocs\\.go\\.th/librarian/get\\?sysid=\\d+&ext=(\\w+))'\"\n",
    "    matches = re.findall(pattern, html)\n",
    "    \n",
    "    for url, ext in matches:\n",
    "        if ext == 'pdf':\n",
    "            if 'icon_en' in html and url == matches[-1][0]:\n",
    "                links['en_pdf'] = url\n",
    "            else:\n",
    "                links['pdf'] = url\n",
    "        elif ext == 'htm':\n",
    "            links['html'] = url\n",
    "        elif ext == 'tif':\n",
    "            links['tif'] = url\n",
    "    base_url = matches[0][0].rsplit('ext=', 1)[0]\n",
    "    links['doc'] = base_url + 'ext=doc'\n",
    "       \n",
    "    \n",
    "    return links\n",
    "\n",
    "# law_df =law_df.join(law_df['law_link'].apply(extract_links).apply(pd.Series))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da13bb0-b010-4529-a6d1-83a146dc385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download for row\n",
    "def download_file(url):\n",
    "    folder = r'/Users/nachanon/Documents/law_extract/files'\n",
    "    os.makedirs(folder , exist_ok = True)\n",
    "    #check url is not nan\n",
    "    if pd.isna(url):\n",
    "        return None\n",
    "\n",
    "    #get path , filename \n",
    "    filename = str(url).split('=')[1].split('&')[0]\n",
    "    ext = url.split('=')[2]\n",
    "    full_name = filename + '.' + ext\n",
    "    file_path = os.path.join(folder, full_name)\n",
    "\n",
    "    #check url if there is a htm file should fill getfile in url to get content\n",
    "    if ext == 'htm' or ext == 'html':\n",
    "        if 'getfile' not in url:\n",
    "            url = url.replace('get','getfile')\n",
    "    response = requests.get(url , stream = True , verify = False )  \n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded: {file_path}\")\n",
    "\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            print(f\"Warning: Downloaded file is empty: {file_path}\")\n",
    "            os.remove(file_path)\n",
    "            return None\n",
    "        \n",
    "        print(f\"Completely downloaded: {file_path}\")\n",
    "        return file_path\n",
    "    else:\n",
    "        print(f'Fail to downloaded: {file_path}')\n",
    "        return None\n",
    "#encap for all file extension cols\n",
    "def download_all_file(row):\n",
    "    ext_cols = ['pdf','html','doc','tif','en_pdf']\n",
    "    for ext in ext_cols:\n",
    "        if ext in row.index:\n",
    "            row[f'{ext}_path'] = download_file(row[ext])\n",
    "        else:\n",
    "            print(f'{ext} not found in this row!!')\n",
    "    return row\n",
    "# law_df = law_df.apply(download_all_file, axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcb574-8f2f-4c83-b184-2e36fd8152c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_store = r\"\\\\wsl.localhost\\Ubuntu-20.04\\home\\tete\\lawpdf_scraping3\\files\"\n",
    "thai_consonants = [chr(i) for i in range(0x0E01, 0x0E2E + 1) if i not in [0x0E24, 0x0E26]]\n",
    "\n",
    "h = html2text.HTML2Text()\n",
    "h.ignore_links = True\n",
    "\n",
    "for alpha in thai_consonants:\n",
    "    alpha_url = f\"https://krisdika.ocs.go.th/th/web/guest/law?p_p_id=LawPortlet_INSTANCE_aAN7C2U5hENi&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_cacheability=cacheLevelPage&p_p_lifecycle=1&_LawPortlet_INSTANCE_aAN7C2U5hENi_character={alpha}&_LawPortlet_INSTANCE_aAN7C2U5hENi_javax.portlet.action=selectCharacterMenu&_LawPortlet_INSTANCE_aAN7C2U5hENi_groupOfAct=byCharacter&_LawPortlet_INSTANCE_aAN7C2U5hENi_lawTypeId=2\"\n",
    "    alpha_response = requests.request(\"GET\",alpha_url, verify=False)\n",
    "    alpha_json = json.loads(alpha_response.text)['rows']\n",
    "    \n",
    "    law_list,ann_list = extract_json(alpha_json)\n",
    "    law_df = pd.DataFrame(law_list)\n",
    "    ann_df = pd.DataFrame(ann_list)\n",
    "\n",
    "    law_df =law_df.join(law_df['law_link'].apply(extract_links).apply(pd.Series))\n",
    "    law_df = law_df.apply(download_all_file, axis =1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
